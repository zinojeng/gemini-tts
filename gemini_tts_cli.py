#!/usr/bin/env python3
"""
Gemini TTS å‘½ä»¤åˆ—å·¥å…·
æ”¯æ´å–®ä¸€è¬›è€…å’Œå¤šè¬›è€…æ–‡å­—è½‰èªéŸ³
"""

import os
import sys
import wave
import argparse
import json
from google import genai
from google.genai import types
from typing import List, Dict
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# èªéŸ³é¸é …
VOICES = [
    "Zephyr", "Puck", "Charon", "Kore", "Fenrir", "Leda", "Orus", "Aoede",
    "Callirrhoe", "Autonoe", "Enceladus", "Iapetus", "Umbriel", "Algieba",
    "Despina", "Erinome", "Algenib", "Rasalgethi", "Laomedeia", "Achernar",
    "Alnilam", "Schedar", "Gacrux", "Pulcherrima", "Achird", "Zubenelgenubi",
    "Vindemiatrix", "Sadachbia", "Sadaltager", "Sulafat"
]

def save_wave_file(filename: str, pcm_data: bytes, channels: int = 1, rate: int = 24000, sample_width: int = 2):
    """å„²å­˜ PCM è³‡æ–™ç‚º WAV æª”æ¡ˆ"""
    with wave.open(filename, "wb") as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(sample_width)
        wf.setframerate(rate)
        wf.writeframes(pcm_data)

def single_speaker_tts(client, model: str, text: str, voice: str, output_file: str):
    """å–®ä¸€è¬›è€… TTS"""
    print(f"ä½¿ç”¨èªéŸ³ {voice} ç”Ÿæˆå–®ä¸€è¬›è€…èªéŸ³...")
    
    response = client.models.generate_content(
        model=model,
        contents=text,
        config=types.GenerateContentConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name=voice
                    )
                )
            )
        )
    )
    
    audio_data = response.candidates[0].content.parts[0].inline_data.data
    save_wave_file(output_file, audio_data)
    print(f"âœ… èªéŸ³å·²å„²å­˜è‡³ï¼š{output_file}")

def multi_speaker_tts(client, model: str, dialogue_file: str, output_file: str):
    """å¤šè¬›è€… TTS"""
    # è®€å–å°è©±æª”æ¡ˆ
    with open(dialogue_file, 'r', encoding='utf-8') as f:
        dialogue_data = json.load(f)
    
    speakers = dialogue_data.get("speakers", [])
    content = dialogue_data.get("content", "")
    
    if len(speakers) < 2:
        raise ValueError("éœ€è¦è‡³å°‘ 2 å€‹è¬›è€…")
    
    print(f"ç”Ÿæˆå¤šè¬›è€…å°è©±ï¼Œè¬›è€…ï¼š{[s['name'] for s in speakers]}")
    
    # å»ºç«‹è¬›è€…é…ç½®
    speaker_voice_configs = []
    for speaker in speakers:
        speaker_voice_configs.append(
            types.SpeakerVoiceConfig(
                speaker=speaker["name"],
                voice_config=types.VoiceConfig(
                    prebuilt_voice_config=types.PrebuiltVoiceConfig(
                        voice_name=speaker["voice"]
                    )
                )
            )
        )
    
    # ç”ŸæˆèªéŸ³
    response = client.models.generate_content(
        model=model,
        contents=f"TTS ä»¥ä¸‹å°è©±ï¼š\n{content}",
        config=types.GenerateContentConfig(
            response_modalities=["AUDIO"],
            speech_config=types.SpeechConfig(
                multi_speaker_voice_config=types.MultiSpeakerVoiceConfig(
                    speaker_voice_configs=speaker_voice_configs
                )
            )
        )
    )
    
    audio_data = response.candidates[0].content.parts[0].inline_data.data
    save_wave_file(output_file, audio_data)
    print(f"âœ… èªéŸ³å·²å„²å­˜è‡³ï¼š{output_file}")

def generate_prompt(prompt_type: str, style: str = None) -> str:
    """ç”Ÿæˆæç¤ºç¯„ä¾‹"""
    prompts = {
        "podcast": "ç”¨ç†±æƒ…çš„æ’­å®¢ä¸»æŒäººèªæ°£èªªï¼šæ­¡è¿å„ä½è½çœ¾ï¼ä»Šå¤©æˆ‘å€‘æœ‰ä¸€å€‹è¶…ç´šç²¾å½©çš„è©±é¡Œè¦å’Œå¤§å®¶åˆ†äº«ã€‚è®“æˆ‘å€‘ä¸€èµ·æ¢ç´¢äººå·¥æ™ºæ…§çš„å¥‡å¦™ä¸–ç•Œï¼",
        "audiobook": "ç”¨æ²‰ç©©çš„æ•˜äº‹èªæ°£æœ—è®€ï¼šæœˆå…‰ç‘åœ¨å¯§éœçš„æ¹–é¢ä¸Šï¼Œå¾®é¢¨è¼•æ‹‚è‘—å²¸é‚Šçš„è˜†è‘¦ã€‚é è™•å‚³ä¾†å¤œé¶¯çš„æ­Œè²ï¼Œç‚ºé€™å€‹å¤å¤œå¢æ·»äº†ä¸€çµ²è©©æ„ã€‚",
        "education": "ç”¨æ¸…æ™°çš„æ•™å­¸èªæ°£èªªï¼šä»Šå¤©æˆ‘å€‘è¦å­¸ç¿’çš„æ˜¯æ©Ÿå™¨å­¸ç¿’çš„åŸºæœ¬æ¦‚å¿µã€‚æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºæ…§çš„ä¸€å€‹åˆ†æ”¯ï¼Œå®ƒè®“é›»è…¦èƒ½å¤ å¾è³‡æ–™ä¸­å­¸ç¿’ï¼Œè€Œä¸éœ€è¦æ˜ç¢ºçš„ç¨‹å¼è¨­è¨ˆã€‚",
        "customer": "ç”¨å‹å–„ã€å°ˆæ¥­çš„èªæ°£èªªï¼šæ‚¨å¥½ï¼æ­¡è¿è‡´é›»å®¢æˆ¶æœå‹™ä¸­å¿ƒã€‚æˆ‘æ˜¯æ‚¨çš„å°ˆå±¬å®¢æœä»£è¡¨ï¼Œå¾ˆé«˜èˆˆç‚ºæ‚¨æä¾›å”åŠ©ã€‚è«‹å•æœ‰ä»€éº¼å¯ä»¥å¹«åŠ©æ‚¨çš„å—ï¼Ÿ"
    }
    
    prompt = prompts.get(prompt_type, "")
    if style:
        prompt = f"{style}åœ°èªªï¼š" + prompt.split("ï¼š", 1)[1] if "ï¼š" in prompt else prompt
    
    return prompt

def main():
    parser = argparse.ArgumentParser(description="Gemini TTS å‘½ä»¤åˆ—å·¥å…·")
    
    # API é‡‘é‘° - å¯å¾ç’°å¢ƒè®Šæ•¸è®€å–
    default_api_key = os.getenv("GEMINI_API_KEY")
    parser.add_argument("--api-key", 
                       default=default_api_key,
                       help="Gemini API é‡‘é‘° (é è¨­å¾ GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸è®€å–)")
    parser.add_argument("--model", default="gemini-2.5-flash-preview-tts", 
                       choices=["gemini-2.5-flash-preview-tts", "gemini-2.5-pro-preview-tts"],
                       help="TTS æ¨¡å‹")
    parser.add_argument("--mode", choices=["single", "multi"], default="single", help="TTS æ¨¡å¼")
    parser.add_argument("--output", "-o", default="output.wav", help="è¼¸å‡ºæª”æ¡ˆåç¨±")
    
    # å–®ä¸€è¬›è€…åƒæ•¸
    parser.add_argument("--text", "-t", help="è¦è½‰æ›çš„æ–‡å­—ï¼ˆå–®ä¸€è¬›è€…æ¨¡å¼ï¼‰")
    parser.add_argument("--voice", "-v", choices=VOICES, default="Kore", help="èªéŸ³é¸æ“‡")
    parser.add_argument("--prompt-type", choices=["podcast", "audiobook", "education", "customer"],
                       help="ä½¿ç”¨é è¨­æç¤ºé¡å‹")
    parser.add_argument("--style", help="èªéŸ³é¢¨æ ¼ï¼ˆå¦‚ï¼šèˆˆå¥®çš„ã€å¹³éœçš„ã€ç¥ç§˜çš„ï¼‰")
    
    # å¤šè¬›è€…åƒæ•¸
    parser.add_argument("--dialogue", "-d", help="å°è©± JSON æª”æ¡ˆè·¯å¾‘ï¼ˆå¤šè¬›è€…æ¨¡å¼ï¼‰")
    parser.add_argument("--create-dialogue-template", action="store_true", 
                       help="å»ºç«‹å°è©±ç¯„æœ¬æª”æ¡ˆ")
    
    # å…¶ä»–åƒæ•¸
    parser.add_argument("--list-voices", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨èªéŸ³")
    
    args = parser.parse_args()
    
    # åˆ—å‡ºèªéŸ³é¸é …
    if args.list_voices:
        print("å¯ç”¨èªéŸ³é¸é …ï¼š")
        for i, voice in enumerate(VOICES, 1):
            print(f"{i:2d}. {voice}")
        return
    
    # å»ºç«‹å°è©±ç¯„æœ¬
    if args.create_dialogue_template:
        template = {
            "speakers": [
                {"name": "ä¸»æŒäºº", "voice": "Kore"},
                {"name": "å˜‰è³“", "voice": "Puck"}
            ],
            "content": """ä¸»æŒäººï¼šæ­¡è¿ä¾†åˆ°æˆ‘å€‘çš„ç¯€ç›®ï¼ä»Šå¤©æˆ‘å€‘æœ‰ä¸€ä½ç‰¹åˆ¥çš„å˜‰è³“ã€‚
å˜‰è³“ï¼šè¬è¬é‚€è«‹ï¼å¾ˆé«˜èˆˆèƒ½ä¾†åˆ°é€™è£¡ã€‚
ä¸»æŒäººï¼šè®“æˆ‘å€‘é–‹å§‹ä»Šå¤©çš„è©±é¡Œå§ã€‚
å˜‰è³“ï¼šå¥½çš„ï¼Œæˆ‘å·²ç¶“æº–å‚™å¥½äº†ï¼"""
        }
        
        with open("dialogue_template.json", "w", encoding="utf-8") as f:
            json.dump(template, f, ensure_ascii=False, indent=2)
        
        print("âœ… å°è©±ç¯„æœ¬å·²å»ºç«‹ï¼šdialogue_template.json")
        return
    
    # æª¢æŸ¥ API é‡‘é‘°
    if not args.api_key:
        print("âŒ æœªæä¾› API é‡‘é‘°")
        print("ğŸ’¡ è«‹ä½¿ç”¨ --api-key åƒæ•¸æˆ–è¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("   ç¯„ä¾‹ï¼šexport GEMINI_API_KEY=your_api_key_here")
        return
    
    # æª¢æŸ¥ API é‡‘é‘°
    if not args.api_key:
        print("âŒ éŒ¯èª¤ï¼šæœªæä¾› API é‡‘é‘°")
        print("è«‹ä½¿ç”¨ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æä¾› API é‡‘é‘°ï¼š")
        print("1. ä½¿ç”¨ --api-key åƒæ•¸")
        print("2. è¨­å®šç’°å¢ƒè®Šæ•¸ GEMINI_API_KEY")
        print("3. åœ¨ .env æª”æ¡ˆä¸­è¨­å®š GEMINI_API_KEY")
        return
    
    # åˆå§‹åŒ–å®¢æˆ¶ç«¯
    try:
        client = genai.Client(api_key=args.api_key)
    except Exception as e:
        print(f"âŒ ç„¡æ³•åˆå§‹åŒ– Gemini å®¢æˆ¶ç«¯ï¼š{e}")
        return
    
    # åŸ·è¡Œ TTS
    try:
        if args.mode == "single":
            # å–®ä¸€è¬›è€…æ¨¡å¼
            if args.prompt_type:
                text = generate_prompt(args.prompt_type, args.style)
            elif args.text:
                text = args.text
                if args.style:
                    text = f"{args.style}åœ°èªªï¼š{text}"
            else:
                print("âŒ è«‹æä¾› --text åƒæ•¸æˆ–ä½¿ç”¨ --prompt-type")
                return
            
            single_speaker_tts(client, args.model, text, args.voice, args.output)
            
        else:
            # å¤šè¬›è€…æ¨¡å¼
            if not args.dialogue:
                print("âŒ å¤šè¬›è€…æ¨¡å¼éœ€è¦æä¾› --dialogue åƒæ•¸")
                print("ğŸ’¡ æç¤ºï¼šä½¿ç”¨ --create-dialogue-template å»ºç«‹ç¯„æœ¬")
                return
            
            multi_speaker_tts(client, args.model, args.dialogue, args.output)
    
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±æ•—ï¼š{e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 